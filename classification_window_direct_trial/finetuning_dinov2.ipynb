{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organizing train/val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset organized successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Set paths\n",
    "source_dir = 'cat_dog_data/images'\n",
    "target_dir = 'cat_dog_data/organized'\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# Create train and val directories for each class\n",
    "for split in ['train', 'val']:\n",
    "    os.makedirs(os.path.join(target_dir, split, 'cat'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(target_dir, split, 'dog'), exist_ok=True)\n",
    "\n",
    "# Define split ratio\n",
    "train_ratio = 0.8  # 80% for training, 20% for validation\n",
    "\n",
    "# Gather and split images\n",
    "cat_images = [img for img in os.listdir(source_dir) if img[0].isupper()]\n",
    "dog_images = [img for img in os.listdir(source_dir) if img[0].islower()]\n",
    "\n",
    "# Split images into training and validation\n",
    "for images, label in [(cat_images, 'cat'), (dog_images, 'dog')]:\n",
    "    random.shuffle(images)\n",
    "    train_count = int(train_ratio * len(images))\n",
    "    train_images = images[:train_count]\n",
    "    val_images = images[train_count:]\n",
    "    \n",
    "    # Move files\n",
    "    for img in train_images:\n",
    "        shutil.move(os.path.join(source_dir, img), os.path.join(target_dir, 'train', label, img))\n",
    "    for img in val_images:\n",
    "        shutil.move(os.path.join(source_dir, img), os.path.join(target_dir, 'val', label, img))\n",
    "\n",
    "print(\"Dataset organized successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A matching Triton is not available, some optimizations will not be enabled.\n",
      "Error caught was: No module named 'triton'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Args object at 0x0000020F7C5F0CD0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CodesNStuffs\\DinoV2_Classification\\dinov2\\dinov2\\layers\\swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is available (SwiGLU)\")\n",
      "d:\\CodesNStuffs\\DinoV2_Classification\\dinov2\\dinov2\\layers\\attention.py:27: UserWarning: xFormers is available (Attention)\n",
      "  warnings.warn(\"xFormers is available (Attention)\")\n",
      "d:\\CodesNStuffs\\DinoV2_Classification\\dinov2\\dinov2\\layers\\block.py:33: UserWarning: xFormers is available (Block)\n",
      "  warnings.warn(\"xFormers is available (Block)\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models\n",
    "from torch.utils.data import DataLoader\n",
    "from functools import partial\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import argparse\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('dinov2')\n",
    "\n",
    "from dinov2.eval.linear import create_linear_input\n",
    "from dinov2.eval.linear import LinearClassifier\n",
    "from dinov2.eval.utils import ModelWithIntermediateLayers\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Fine-tune DINOv2 on ImageNet100')\n",
    "parser.add_argument('--arch', '-a', metavar='ARCH', default='dinov2_vitb14', choices=['dinov2_vitb14', 'dinov2_vitl14'],\n",
    "                    help='')\n",
    "parser.add_argument('--batch-size', '-b', default=128, type=int, metavar='N',\n",
    "                    help='mini-batch size (default: 128)')\n",
    "parser.add_argument('--log-dir', default='./', type=str, metavar='PATH',\n",
    "                    help='path to directory where to log (default: current directory)')\n",
    "parser.add_argument('--data-dir', required=True, type=str, metavar='PATH',\n",
    "                    help='path to the dataset')\n",
    "\n",
    "\n",
    "class Args:\n",
    "    arch = 'dinov2_vitb14'\n",
    "    batch_size = 128\n",
    "    log_dir = './'\n",
    "    data_dir = 'cat_dog_data/organized'  # Change to your dataset path\n",
    "\n",
    "args = Args()\n",
    "print(args)\n",
    "\n",
    "if not os.path.exists(args.log_dir):\n",
    "    os.makedirs(args.log_dir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "from functools import partial\n",
    "from dinov2.models import ModelWithIntermediateLayers  # Ensure the DINOv2 model setup is correct\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Modified Dino class to include heatmap functionality\n",
    "class Dino(nn.Module):\n",
    "    def __init__(self, type, num_classes=100):\n",
    "        super().__init__()\n",
    "        # Load the feature model\n",
    "        model = torch.hub.load(\n",
    "            \"facebookresearch/dinov2\", type, pretrained=True\n",
    "        ).to(device)\n",
    "\n",
    "        # Use autocast for mixed precision\n",
    "        autocast_ctx = partial(\n",
    "            torch.cuda.amp.autocast, enabled=True, dtype=torch.float16\n",
    "        )\n",
    "        self.feature_model = ModelWithIntermediateLayers(\n",
    "            model, n_last_blocks=1, autocast_ctx=autocast_ctx, return_all_patches=True\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Test a sample input to get feature shapes\n",
    "            sample_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "            sample_output = self.feature_model(sample_input)\n",
    "            patch_features = sample_output[\"patch_tokens\"]\n",
    "            print(f\"Patch feature shape: {patch_features.shape}\")\n",
    "\n",
    "        # Create a linear classifier for patch features\n",
    "        out_dim = patch_features.shape[-1]\n",
    "        self.classifier = nn.Linear(out_dim, num_classes).to(device)\n",
    "\n",
    "    def forward(self, x, target_class=None):\n",
    "        features = self.feature_model(x)\n",
    "        patch_tokens = features[\"patch_tokens\"]  # Extract patch features (B, N, D)\n",
    "\n",
    "        # Classify each patch\n",
    "        patch_scores = self.classifier(patch_tokens)  # (B, N, num_classes)\n",
    "\n",
    "        if target_class is not None:\n",
    "            # Generate heatmap for the target class\n",
    "            heatmap = patch_scores.softmax(dim=-1)[..., target_class]  # Class probability map (B, N)\n",
    "            return patch_scores, heatmap\n",
    "        else:\n",
    "            # Aggregate patch scores for classification\n",
    "            aggregated_scores = patch_scores.mean(dim=1)  # Average over patches (B, num_classes)\n",
    "            return aggregated_scores\n",
    "\n",
    "\n",
    "# Define transforms for the training and validation datasets\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(args.data_dir, x), data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32,\n",
    "                                                   shuffle=True, num_workers=4)\n",
    "                    for x in ['train', 'val']}\n",
    "\n",
    "# Initialize model\n",
    "model = Dino(args.arch, num_classes=100).to(device)\n",
    "\n",
    "# Freeze feature model parameters\n",
    "for param in model.feature_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Train only the classifier\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Define loss function, optimizer, and learning rate scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.classifier.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 25\n",
    "best_acc = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    for phase in ['train', 'val']:\n",
    "        start_time = time.time()\n",
    "\n",
    "        if phase == 'train':\n",
    "            model.feature_model.eval()  # Freeze feature model\n",
    "            model.classifier.train()\n",
    "        else:\n",
    "            model.feature_model.eval()\n",
    "            model.classifier.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in tqdm(dataloaders_dict[phase]):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # Extract features without gradients\n",
    "                features = model.feature_model(inputs)[\"patch_tokens\"]\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                # Forward pass through the classifier\n",
    "                outputs = model.classifier(features.mean(dim=1))  # Aggregate patch scores\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(image_datasets[phase])\n",
    "        epoch_acc = running_corrects.double() / len(image_datasets[phase])\n",
    "\n",
    "        time_elapsed = time.time() - start_time\n",
    "        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} Time: {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "\n",
    "        # Save the best model\n",
    "        if phase == 'val' and epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            torch.save(model.state_dict(), os.path.join(args.log_dir, 'best_model.pth'))\n",
    "\n",
    "    print()\n",
    "\n",
    "print('Training complete')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dinov2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
