{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# Dataset Definition\n",
    "class ImagePairsDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.data = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        img1_path, img2_path, label = row[\"Image1\"], row[\"Image2\"], row[\"Label\"]\n",
    "\n",
    "        # Load images\n",
    "        img1 = Image.open(img1_path).convert(\"RGB\")\n",
    "        img2 = Image.open(img2_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "\n",
    "        return img1, img2, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "# K-Fold Data Preparation\n",
    "def prepare_data_kfold(df_path, k=5, batch_size=8):\n",
    "    df = pd.read_csv(df_path)\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    splits = list(kf.split(df))\n",
    "\n",
    "    transform = T.Compose([\n",
    "        T.Resize((224, 224)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # Prepare loaders for each fold\n",
    "    loaders = []\n",
    "    for i, (train_idx, test_idx) in enumerate(splits):\n",
    "        train_df = df.iloc[train_idx]\n",
    "        test_df = df.iloc[test_idx]\n",
    "\n",
    "        train_dataset = ImagePairsDataset(train_df, transform=transform)\n",
    "        test_dataset = ImagePairsDataset(test_df, transform=transform)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        loaders.append((train_loader, test_loader))\n",
    "\n",
    "    return loaders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# ResNet Block Definition\n",
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.skip_connection = nn.Identity() if in_channels == out_channels else nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = self.skip_connection(x)\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += identity\n",
    "        return self.relu(out)\n",
    "\n",
    "# ResNet with 3 Residual Blocks\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_blocks=3):\n",
    "        super(ResNet, self).__init__()\n",
    "        layers = []\n",
    "        for _ in range(num_blocks):\n",
    "            layers.append(ResNetBlock(in_channels, out_channels))\n",
    "            in_channels = out_channels  # Output of one block becomes input for the next\n",
    "        self.resnet_blocks = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet_blocks(x)\n",
    "\n",
    "# Feature Extractor using DINOv2\n",
    "class DINOFeatureExtractor(torch.nn.Module):\n",
    "    def __init__(self, backbone):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# Model for Visual Disambiguation with ResNet blocks\n",
    "class VisualDisambiguationModelWithResNet(torch.nn.Module):\n",
    "    def __init__(self, feature_dim, backbone, resnet_in_channels, resnet_out_channels):\n",
    "        super().__init__()\n",
    "        # DINO backbone feature extractor\n",
    "        self.dino_feature_extractor = DINOFeatureExtractor(backbone)\n",
    "        \n",
    "        # ResNet with 3 residual blocks\n",
    "        self.resnet = ResNet(resnet_in_channels, resnet_out_channels, num_blocks=3)\n",
    "\n",
    "        # Visual Disambiguation classifier\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(feature_dim * 2, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            torch.nn.Linear(512, 1),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # Pass both inputs through DINO backbone and ResNet blocks\n",
    "        features1 = self.dino_feature_extractor(x1)\n",
    "        features2 = self.dino_feature_extractor(x2)\n",
    "\n",
    "        features1 = self.resnet(features1)\n",
    "        features2 = self.resnet(features2)\n",
    "\n",
    "        # Flatten the features\n",
    "        features1 = features1.flatten(start_dim=1)\n",
    "        features2 = features2.flatten(start_dim=1)\n",
    "\n",
    "        # Pass features to the classifier\n",
    "        combined_features = torch.cat([features1, features2], dim=1)\n",
    "        return self.classifier(combined_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and eval function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm  # Import tqdm for progress bar\n",
    "\n",
    "# Training Loop\n",
    "def train_model(train_loader, model, feature_extractor, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    feature_extractor.eval()  # Freeze DINO\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Use tqdm to show progress bar\n",
    "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "        for img1, img2, labels in tepoch:\n",
    "            img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)\n",
    "\n",
    "            features1 = feature_extractor(img1)\n",
    "            features2 = feature_extractor(img2)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features1, features2).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Update progress bar description with loss information\n",
    "            tepoch.set_postfix(loss=running_loss / (tepoch.n + 1))\n",
    "\n",
    "    return running_loss / len(train_loader)\n",
    "\n",
    "# Evaluation\n",
    "def evaluate_model(test_loader, model, feature_extractor, criterion, device):\n",
    "    model.eval()\n",
    "    feature_extractor.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Use tqdm to show progress bar for evaluation\n",
    "    with tqdm(test_loader, unit=\"batch\") as tepoch:\n",
    "        with torch.no_grad():\n",
    "            for img1, img2, labels in tepoch:\n",
    "                img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)\n",
    "\n",
    "                features1 = feature_extractor(img1)\n",
    "                features2 = feature_extractor(img2)\n",
    "\n",
    "                outputs = model(features1, features2).squeeze()\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                preds = (outputs > 0.5).float()\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # Update progress bar description with loss information\n",
    "                tepoch.set_postfix(loss=running_loss / (tepoch.n + 1))\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return running_loss / len(test_loader), accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\user/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
      "A matching Triton is not available, some optimizations will not be enabled.\n",
      "Error caught was: No module named 'triton'\n",
      "C:\\Users\\user/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is available (SwiGLU)\")\n",
      "C:\\Users\\user/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\attention.py:27: UserWarning: xFormers is available (Attention)\n",
      "  warnings.warn(\"xFormers is available (Attention)\")\n",
      "C:\\Users\\user/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\block.py:33: UserWarning: xFormers is available (Block)\n",
      "  warnings.warn(\"xFormers is available (Block)\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?batch/s]c:\\Users\\user\\anaconda3\\envs\\dinov2_env\\lib\\site-packages\\xformers\\ops\\unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage_data_ptr = tensors[0].storage().data_ptr()\n",
      "c:\\Users\\user\\anaconda3\\envs\\dinov2_env\\lib\\site-packages\\xformers\\ops\\unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  if x.storage().data_ptr() != storage_data_ptr:\n",
      "100%|██████████| 500/500 [16:57<00:00,  2.03s/batch, loss=0.613]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.6132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [17:51<00:00,  2.14s/batch, loss=0.525]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.5254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [17:52<00:00,  2.15s/batch, loss=0.467]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.4668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [18:13<00:00,  2.19s/batch, loss=0.419]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.4187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [17:20<00:00,  2.08s/batch, loss=0.367]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.3674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05batch/s, loss=0.356]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Test Loss: 0.3557, Accuracy: 86.2000%\n",
      "Fold 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [17:26<00:00,  2.09s/batch, loss=0.342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.3420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [17:05<00:00,  2.05s/batch, loss=0.294]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.2943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [15:20<00:00,  1.84s/batch, loss=0.259]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.2586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [15:13<00:00,  1.83s/batch, loss=0.241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.2409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [15:16<00:00,  1.83s/batch, loss=0.22] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.2197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:33<00:00,  1.17batch/s, loss=0.211]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Test Loss: 0.2111, Accuracy: 90.8000%\n",
      "Fold 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [15:35<00:00,  1.87s/batch, loss=0.223]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.2234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [15:17<00:00,  1.84s/batch, loss=0.205]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.2050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [15:28<00:00,  1.86s/batch, loss=0.189]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.1890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [15:19<00:00,  1.84s/batch, loss=0.18] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.1798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [15:16<00:00,  1.83s/batch, loss=0.171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.1711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:26<00:00,  1.21batch/s, loss=0.171]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Test Loss: 0.1707, Accuracy: 92.3500%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.hub\n",
    "\n",
    "df_path = \"Arc_de_T_6k.csv\"\n",
    "k = 3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load data with K-Fold\n",
    "loaders = prepare_data_kfold(df_path, k)\n",
    "\n",
    "# Load DINOv2 Backbone\n",
    "backbone = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitb14').to(device)\n",
    "feature_extractor = DINOFeatureExtractor(backbone).to(device)\n",
    "\n",
    "# Model, Optimizer, Loss\n",
    "model = VisualDisambiguationModel(feature_dim=768).to(device)  # vitl14 output dim is 1024, vitb14 is 768 \n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "for fold, (train_loader, test_loader) in enumerate(loaders):\n",
    "    print(f\"Fold {fold + 1}/{k}\")\n",
    "\n",
    "    # Train\n",
    "    for epoch in range(5):  #5 epochs per fold\n",
    "        train_loss = train_model(train_loader, model, feature_extractor, optimizer, criterion, device)\n",
    "        print(f\"Epoch {epoch + 1}, Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "    # Evaluate\n",
    "    test_loss, accuracy = evaluate_model(test_loader, model, feature_extractor, criterion, device)\n",
    "    print(f\"Fold {fold + 1} - Test Loss: {test_loss:.4f}, Accuracy: {accuracy:.4%}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to Arc_de_T_model.pth\n"
     ]
    }
   ],
   "source": [
    "model_save_path = \"Arc_de_T_model.pth\"\n",
    "\n",
    "# Save both the model's state_dict and the feature extractor (optional)\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'feature_extractor_state_dict': feature_extractor.state_dict(),\n",
    "}, model_save_path)\n",
    "\n",
    "print(f\"Model saved to {model_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dinov2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
